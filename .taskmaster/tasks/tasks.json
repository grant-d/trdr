{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup and Core Interfaces",
        "description": "Initialize the TypeScript project with necessary dependencies and implement core interfaces for the data pipeline.",
        "details": "1. Initialize a new TypeScript project with npm\n2. Configure TypeScript, ESLint, and testing framework (node:test)\n3. Set up Winston for structured logging\n4. Implement core interfaces:\n   - `OhlcvDto` interface for market data\n   - `DataProvider` interface for data sources\n   - `Transform` interface for pipeline transformations\n   - Basic pipeline executor\n5. Create project directory structure\n\n```typescript\n// Example core interfaces implementation\ninterface OhlcvDto {\n  exchange: string;\n  symbol: string;\n  timestamp: number; // UTC unix timestamp in milliseconds\n  open: number;\n  high: number;\n  low: number;\n  close: number;\n  volume: number;\n  [key: string]: number | string; // For additional columns added by transforms\n}\n\ninterface DataProvider {\n  name: string;\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  getHistoricalData(params: HistoricalParams): AsyncIterator<OhlcvDto>;\n  subscribeRealtime(params: RealtimeParams): AsyncIterator<OhlcvDto>;\n  getRequiredEnvVars(): string[];\n}\n\ninterface Transform {\n  type: TransformType;\n  apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto>;\n  getCoefficients(): Record<string, number> | null;\n}\n```",
        "testStrategy": "1. Unit tests for each interface implementation\n2. Verify TypeScript compilation works correctly\n3. Test logging configuration with different log levels\n4. Validate project structure follows best practices\n5. Ensure ESLint rules are properly enforced",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "File-Based Data Provider Implementation",
        "description": "Implement the FileProvider to handle CSV and Parquet files with configurable column mapping and streaming processing.",
        "details": "1. Create a `FileProvider` class implementing the `DataProvider` interface\n2. Implement streaming CSV reader that processes data in chunks\n3. Add support for configurable column mapping\n4. Implement Parquet file support using parquet-wasm or arrow\n5. Ensure all file operations are streaming to avoid memory issues\n6. Standardize timestamps to UTC milliseconds\n7. Add validation for OHLC relationships (high â‰¥ low, etc.)\n\n```typescript\nclass FileProvider implements DataProvider {\n  name = 'file';\n  private filePath: string;\n  private format: 'csv' | 'parquet';\n  private columnMapping: ColumnMapping;\n  \n  constructor(config: FileProviderConfig) {\n    this.filePath = config.path;\n    this.format = config.format || this.detectFormatFromExtension(config.path);\n    this.columnMapping = config.columnMapping || this.getDefaultColumnMapping();\n  }\n  \n  async connect(): Promise<void> {\n    // Validate file exists and is readable\n  }\n  \n  async disconnect(): Promise<void> {\n    // Close any open file handles\n  }\n  \n  async *getHistoricalData(params: HistoricalParams): AsyncIterator<OhlcvDto> {\n    // Create readable stream for file\n    // Process in chunks (e.g., 1000 rows at a time)\n    // Map columns according to columnMapping\n    // Validate and standardize data\n    // Yield standardized OhlcvDto objects\n  }\n  \n  async *subscribeRealtime(): AsyncIterator<OhlcvDto> {\n    throw new Error('FileProvider does not support real-time data');\n  }\n  \n  getRequiredEnvVars(): string[] {\n    return [];\n  }\n  \n  private detectFormatFromExtension(path: string): 'csv' | 'parquet' {\n    // Auto-detect format from file extension\n  }\n  \n  private getDefaultColumnMapping(): ColumnMapping {\n    // Return default column mapping\n  }\n}\n```",
        "testStrategy": "1. Unit tests with sample CSV and Parquet files\n2. Test with different column mappings\n3. Verify streaming works with large files (>100MB)\n4. Test error handling for invalid files\n5. Benchmark performance with different batch sizes\n6. Verify memory usage remains constant regardless of file size",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Storage Layer Implementation",
        "description": "Implement the storage layer with repository pattern for SQLite, CSV, and Parquet outputs with proper indexing and streaming writes.",
        "details": "1. Create `OhlcvRepository` interface\n2. Implement concrete repositories for each output type:\n   - `SqliteRepository`\n   - `CsvRepository`\n   - `ParquetRepository`\n3. Set up SQLite schema with proper indexing for time-series data\n4. Implement batch inserts with immediate disk writes\n5. Add support for coefficient storage\n6. Implement append-only writes to prevent memory buildup\n\n```typescript\ninterface OhlcvRepository {\n  initialize(): Promise<void>;\n  appendBatch(data: OhlcvDto[]): Promise<void>;\n  getLastTimestamp(symbol: string): Promise<number | null>;\n  storeCoefficients(symbol: string, transform: string, coefficients: Record<string, number>): Promise<void>;\n  getCoefficients(symbol: string, transform: string): Promise<Record<string, number> | null>;\n  close(): Promise<void>;\n}\n\nclass SqliteRepository implements OhlcvRepository {\n  private db: Database;\n  private table: string;\n  private batchSize: number;\n  \n  constructor(config: SqliteConfig) {\n    this.db = new Database(config.database);\n    this.table = config.table;\n    this.batchSize = config.batchSize || 1000;\n  }\n  \n  async initialize(): Promise<void> {\n    // Create tables if they don't exist\n    // Set up indexes on timestamp, symbol\n    // Prepare statements for batch inserts\n  }\n  \n  async appendBatch(data: OhlcvDto[]): Promise<void> {\n    // Use transaction for batch insert\n    // Handle dynamic columns from transforms\n  }\n  \n  async getLastTimestamp(symbol: string): Promise<number | null> {\n    // Query for most recent timestamp for a symbol\n  }\n  \n  async storeCoefficients(symbol: string, transform: string, coefficients: Record<string, number>): Promise<void> {\n    // Store transform coefficients with timestamp range\n  }\n  \n  async getCoefficients(symbol: string, transform: string): Promise<Record<string, number> | null> {\n    // Retrieve most recent coefficients for symbol/transform\n  }\n  \n  async close(): Promise<void> {\n    // Close database connection\n  }\n}\n```",
        "testStrategy": "1. Unit tests for each repository implementation\n2. Test batch inserts with various sizes\n3. Verify proper indexing with query performance tests\n4. Test coefficient storage and retrieval\n5. Verify append-only behavior works correctly\n6. Test with large datasets to ensure memory usage remains constant",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Core Transformations Implementation",
        "description": "Implement the essential data transformations including missing value handling, timeframe aggregation, and normalization.",
        "details": "1. Create base `Transform` abstract class\n2. Implement `MissingValueHandler` transform with forward fill, interpolation strategies\n3. Implement `TimeframeAggregator` for flexible OHLC aggregation\n4. Implement `Normalizer` transforms (log returns, z-score, min-max)\n5. Implement `PriceCalculations` (HLC3, OHLC4, typical price)\n6. Ensure all transforms process data in a streaming fashion\n7. Add coefficient tracking for reversible transforms\n\n```typescript\nabstract class BaseTransform implements Transform {\n  protected type: TransformType;\n  protected coefficients: Record<string, number> | null = null;\n  \n  constructor(type: TransformType) {\n    this.type = type;\n  }\n  \n  abstract async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto>;\n  \n  getCoefficients(): Record<string, number> | null {\n    return this.coefficients;\n  }\n}\n\nclass TimeframeAggregator extends BaseTransform {\n  private targetTimeframe: string;\n  private alignToMarketOpen: boolean;\n  private currentBars: Map<string, OhlcvDto> = new Map();\n  \n  constructor(params: TimeframeAggregationParams) {\n    super('timeframeAggregation');\n    this.targetTimeframe = params.targetTimeframe;\n    this.alignToMarketOpen = params.alignToMarketOpen || false;\n  }\n  \n  async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto> {\n    // Calculate target timeframe in milliseconds\n    // Process incoming bars\n    // Aggregate into target timeframe\n    // Emit completed bars\n    // Handle final incomplete bars\n  }\n  \n  private getTargetTimestamp(timestamp: number): number {\n    // Calculate aligned timestamp for the target timeframe\n  }\n}\n\nclass LogReturnsNormalizer extends BaseTransform {\n  private base: 'natural' | 'log10';\n  \n  constructor(params: LogReturnsParams) {\n    super('logReturns');\n    this.base = params.base || 'natural';\n  }\n  \n  async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto> {\n    let prevClose: Record<string, number> = {};\n    \n    for await (const bar of data) {\n      const symbol = bar.symbol;\n      if (prevClose[symbol] !== undefined && prevClose[symbol] > 0) {\n        const logReturn = this.base === 'natural'\n          ? Math.log(bar.close / prevClose[symbol])\n          : Math.log10(bar.close / prevClose[symbol]);\n        \n        // Create new bar with log return\n        const newBar = { ...bar, log_return: logReturn };\n        yield newBar;\n      } else {\n        // First bar, no return can be calculated\n        yield { ...bar, log_return: null };\n      }\n      \n      prevClose[symbol] = bar.close;\n    }\n  }\n}\n```",
        "testStrategy": "1. Unit tests for each transform with sample data\n2. Test edge cases (missing data, zero values, etc.)\n3. Verify timeframe aggregation works with various multiples\n4. Test reversibility of normalizations\n5. Benchmark performance with large datasets\n6. Verify memory usage remains constant during processing",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "CLI Interface and Configuration",
        "description": "Implement the command-line interface with JSON config loading, validation, and pipeline execution.",
        "details": "1. Create CLI entry point with command parsing\n2. Implement JSON config loading and validation\n3. Create pipeline factory to build transforms from config\n4. Add support for config overrides via command flags\n5. Implement progress indicators for long operations\n6. Add interactive mode (process once and exit) and server mode (continuous)\n\n```typescript\ninterface PipelineConfig {\n  name: string;\n  description?: string;\n  input: InputConfig;\n  transformations: TransformConfig[];\n  output: OutputConfig;\n  options?: OptionsConfig;\n}\n\nclass ConfigValidator {\n  validate(config: PipelineConfig): ValidationResult {\n    // Validate config structure\n    // Check for required fields\n    // Validate transform compatibility and ordering\n    // Return validation result with any errors\n  }\n}\n\nclass PipelineFactory {\n  createPipeline(config: PipelineConfig): Pipeline {\n    // Create provider from input config\n    // Create transforms from transformation configs\n    // Create repository from output config\n    // Return assembled pipeline\n  }\n}\n\nasync function main() {\n  // Parse command line arguments\n  const args = parseArgs(process.argv.slice(2));\n  \n  // Load config file\n  const configPath = args.config || 'pipeline.json';\n  const config = await loadConfig(configPath);\n  \n  // Apply command line overrides\n  if (args.override) {\n    applyOverrides(config, args.override);\n  }\n  \n  // Validate config\n  const validator = new ConfigValidator();\n  const validationResult = validator.validate(config);\n  if (!validationResult.valid) {\n    console.error('Invalid configuration:', validationResult.errors);\n    process.exit(1);\n  }\n  \n  // Create and execute pipeline\n  const factory = new PipelineFactory();\n  const pipeline = factory.createPipeline(config);\n  \n  if (config.options?.mode === 'server') {\n    // Run in continuous server mode\n    await pipeline.runContinuously();\n  } else {\n    // Run in interactive mode (once and exit)\n    await pipeline.run();\n  }\n}\n```",
        "testStrategy": "1. Unit tests for config validation\n2. Test with various sample config files\n3. Test command line override functionality\n4. Verify error messages are helpful and clear\n5. Test progress indicators with long-running operations\n6. Integration tests for full pipeline execution",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Coinbase Provider Implementation",
        "description": "Implement the Coinbase provider with REST and WebSocket support, rate limiting, and reconnection logic.",
        "details": "1. Create `CoinbaseProvider` class implementing the `DataProvider` interface\n2. Implement REST API client for historical data\n3. Implement WebSocket client for real-time data\n4. Add rate limiting with exponential backoff\n5. Implement reconnection logic with circuit breaker pattern\n6. Add authentication via environment variables\n7. Implement backfill mechanism for gaps\n\n```typescript\nclass CoinbaseProvider implements DataProvider {\n  name = 'coinbase';\n  private apiKey: string;\n  private apiSecret: string;\n  private wsClient: WebSocket | null = null;\n  private subscriptions: Map<string, Set<string>> = new Map();\n  private retryConfig: RetryConfig;\n  \n  constructor(config: CoinbaseConfig) {\n    this.apiKey = process.env.COINBASE_API_KEY || '';\n    this.apiSecret = process.env.COINBASE_API_SECRET || '';\n    this.retryConfig = config.retryConfig || {\n      maxRetries: 5,\n      backoffMultiplier: 2,\n      maxBackoffSeconds: 60\n    };\n  }\n  \n  async connect(): Promise<void> {\n    if (!this.apiKey || !this.apiSecret) {\n      throw new Error('Coinbase API credentials not found in environment variables');\n    }\n    // Initialize REST client\n  }\n  \n  async disconnect(): Promise<void> {\n    // Close WebSocket connection if open\n    if (this.wsClient) {\n      this.wsClient.close();\n      this.wsClient = null;\n    }\n  }\n  \n  async *getHistoricalData(params: HistoricalParams): AsyncIterator<OhlcvDto> {\n    // Fetch historical data from REST API\n    // Handle pagination\n    // Apply rate limiting\n    // Convert to OhlcvDto format\n    // Yield bars in chronological order\n  }\n  \n  async *subscribeRealtime(params: RealtimeParams): AsyncIterator<OhlcvDto> {\n    // Connect to WebSocket if not already connected\n    await this.ensureWebSocketConnection();\n    \n    // Subscribe to channels for requested symbols\n    for (const symbol of params.symbols) {\n      await this.subscribeToSymbol(symbol, params.timeframe);\n    }\n    \n    // Create and return async iterator that yields real-time bars\n    // Handle reconnections and backfill gaps\n  }\n  \n  getRequiredEnvVars(): string[] {\n    return ['COINBASE_API_KEY', 'COINBASE_API_SECRET'];\n  }\n  \n  private async ensureWebSocketConnection(): Promise<void> {\n    // Create WebSocket connection if not exists\n    // Set up event handlers\n    // Implement reconnection logic\n  }\n  \n  private async subscribeToSymbol(symbol: string, timeframe: string): Promise<void> {\n    // Send subscription message to WebSocket\n    // Track active subscriptions\n  }\n  \n  private async backfill(symbol: string, lastTimestamp: number): Promise<OhlcvDto[]> {\n    // Calculate gap between last timestamp and current time\n    // Fetch missing data via REST API\n    // Return backfilled bars\n  }\n}\n```",
        "testStrategy": "1. Unit tests with mocked API responses\n2. Test rate limiting behavior\n3. Test reconnection logic with simulated disconnections\n4. Verify backfill mechanism works correctly\n5. Test authentication error handling\n6. Integration tests with actual Coinbase API (using test credentials)",
        "priority": "medium",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Technical Indicators Implementation",
        "description": "Implement technical indicators and advanced transformations including moving averages, RSI, Bollinger Bands, and more.",
        "details": "1. Create base class for technical indicators\n2. Implement `MovingAverage` transform (SMA, EMA)\n3. Implement `RSI` transform\n4. Implement `BollingerBands` transform\n5. Implement `MACD` transform\n6. Implement `ATR` transform\n7. Implement `VWAP` transform\n8. Ensure all indicators can use any column as source\n\n```typescript\nabstract class IndicatorTransform extends BaseTransform {\n  protected source: string;\n  protected outputColumn: string;\n  \n  constructor(type: TransformType, source: string = 'close', outputColumn?: string) {\n    super(type);\n    this.source = source;\n    this.outputColumn = outputColumn || `${type}_${this.getDefaultSuffix()}`;\n  }\n  \n  abstract getDefaultSuffix(): string;\n}\n\nclass MovingAverageTransform extends IndicatorTransform {\n  private type: 'sma' | 'ema';\n  private period: number;\n  private values: Map<string, number[]> = new Map();\n  \n  constructor(params: MovingAverageParams) {\n    super('movingAverage', params.source, params.outputColumn);\n    this.type = params.type;\n    this.period = params.period;\n  }\n  \n  getDefaultSuffix(): string {\n    return `${this.type}_${this.period}`;\n  }\n  \n  async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto> {\n    for await (const bar of data) {\n      const symbol = bar.symbol;\n      const value = bar[this.source] as number;\n      \n      if (!this.values.has(symbol)) {\n        this.values.set(symbol, []);\n      }\n      \n      const values = this.values.get(symbol)!;\n      values.push(value);\n      \n      // Keep only necessary history\n      if (values.length > this.period) {\n        values.shift();\n      }\n      \n      // Calculate MA based on type\n      let result: number | null = null;\n      if (values.length === this.period) {\n        if (this.type === 'sma') {\n          result = values.reduce((sum, val) => sum + val, 0) / this.period;\n        } else if (this.type === 'ema') {\n          // EMA calculation\n          // ...\n        }\n      }\n      \n      // Create new bar with indicator value\n      yield { ...bar, [this.outputColumn]: result };\n    }\n  }\n}\n\nclass RSITransform extends IndicatorTransform {\n  private period: number;\n  private prevValues: Map<string, number> = new Map();\n  private gains: Map<string, number[]> = new Map();\n  private losses: Map<string, number[]> = new Map();\n  \n  constructor(params: RSIParams) {\n    super('rsi', params.source, params.outputColumn);\n    this.period = params.period;\n  }\n  \n  getDefaultSuffix(): string {\n    return `${this.period}`;\n  }\n  \n  async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto> {\n    // RSI implementation\n    // ...\n  }\n}\n```",
        "testStrategy": "1. Unit tests for each indicator with known input/output values\n2. Test edge cases (insufficient data, zero values, etc.)\n3. Verify calculations match standard implementations\n4. Test with different source columns\n5. Benchmark performance with large datasets\n6. Verify memory usage remains constant during processing",
        "priority": "medium",
        "dependencies": [
          1,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Alternative Bar Generation and Server Mode",
        "description": "Implement alternative bar types (tick, volume, dollar, tick-imbalance) and continuous server mode with backfill.",
        "details": "1. Implement `TickBarGenerator` transform\n2. Implement `VolumeBarGenerator` transform\n3. Implement `DollarBarGenerator` transform\n4. Implement `TickImbalanceBarGenerator` transform\n5. Implement `HeikinAshiGenerator` transform\n6. Create server mode for continuous operation\n7. Implement gap detection and backfill mechanism\n8. Add graceful shutdown with state persistence\n\n```typescript\nabstract class BarGeneratorTransform extends BaseTransform {\n  protected symbolState: Map<string, any> = new Map();\n  \n  constructor(type: TransformType) {\n    super(type);\n  }\n  \n  abstract isBarComplete(symbol: string, bar: OhlcvDto): boolean;\n  abstract createNewBar(symbol: string, bar: OhlcvDto): OhlcvDto;\n  abstract updateBar(symbol: string, currentBar: OhlcvDto, newBar: OhlcvDto): OhlcvDto;\n  \n  async *apply(data: AsyncIterator<OhlcvDto>): AsyncIterator<OhlcvDto> {\n    for await (const bar of data) {\n      const symbol = bar.symbol;\n      \n      if (!this.symbolState.has(symbol)) {\n        this.symbolState.set(symbol, {\n          currentBar: this.createNewBar(symbol, bar),\n          complete: false\n        });\n        continue;\n      }\n      \n      const state = this.symbolState.get(symbol)!;\n      state.currentBar = this.updateBar(symbol, state.currentBar, bar);\n      \n      if (this.isBarComplete(symbol, bar)) {\n        // Emit completed bar\n        yield state.currentBar;\n        // Start new bar\n        state.currentBar = this.createNewBar(symbol, bar);\n      }\n    }\n    \n    // Emit any final incomplete bars\n    for (const [symbol, state] of this.symbolState.entries()) {\n      if (!state.complete) {\n        yield state.currentBar;\n      }\n    }\n  }\n}\n\nclass VolumeBarGenerator extends BarGeneratorTransform {\n  private volumePerBar: number;\n  private accumulatedVolume: Map<string, number> = new Map();\n  \n  constructor(params: VolumeBarsParams) {\n    super('volumeBars');\n    this.volumePerBar = params.volumePerBar;\n  }\n  \n  isBarComplete(symbol: string, bar: OhlcvDto): boolean {\n    const accVolume = (this.accumulatedVolume.get(symbol) || 0) + bar.volume;\n    this.accumulatedVolume.set(symbol, accVolume);\n    \n    return accVolume >= this.volumePerBar;\n  }\n  \n  createNewBar(symbol: string, bar: OhlcvDto): OhlcvDto {\n    this.accumulatedVolume.set(symbol, bar.volume);\n    return { ...bar };\n  }\n  \n  updateBar(symbol: string, currentBar: OhlcvDto, newBar: OhlcvDto): OhlcvDto {\n    return {\n      ...currentBar,\n      high: Math.max(currentBar.high, newBar.high),\n      low: Math.min(currentBar.low, newBar.low),\n      close: newBar.close,\n      volume: currentBar.volume + newBar.volume,\n      timestamp: newBar.timestamp // Use timestamp of last update\n    };\n  }\n}\n\nclass Pipeline {\n  private provider: DataProvider;\n  private transforms: Transform[];\n  private repository: OhlcvRepository;\n  private options: PipelineOptions;\n  \n  constructor(provider: DataProvider, transforms: Transform[], repository: OhlcvRepository, options: PipelineOptions) {\n    this.provider = provider;\n    this.transforms = transforms;\n    this.repository = repository;\n    this.options = options;\n  }\n  \n  async run(): Promise<void> {\n    // Run pipeline once and exit\n    await this.provider.connect();\n    \n    try {\n      // Get historical data\n      let data = this.provider.getHistoricalData(this.options.historicalParams);\n      \n      // Apply transforms\n      for (const transform of this.transforms) {\n        data = transform.apply(data);\n      }\n      \n      // Process and store results\n      await this.processResults(data);\n    } finally {\n      await this.provider.disconnect();\n      await this.repository.close();\n    }\n  }\n  \n  async runContinuously(): Promise<void> {\n    // Run in server mode\n    await this.provider.connect();\n    await this.repository.initialize();\n    \n    try {\n      // Check for gaps and backfill if needed\n      if (this.options.backfillOnStartup) {\n        await this.backfill();\n      }\n      \n      // Subscribe to real-time data\n      let data = this.provider.subscribeRealtime(this.options.realtimeParams);\n      \n      // Apply transforms\n      for (const transform of this.transforms) {\n        data = transform.apply(data);\n      }\n      \n      // Process and store results continuously\n      await this.processResults(data);\n    } finally {\n      await this.provider.disconnect();\n      await this.repository.close();\n    }\n  }\n  \n  private async backfill(): Promise<void> {\n    // Get last timestamp from repository\n    // Calculate gap\n    // Fetch missing data\n    // Process through pipeline\n    // Store results\n  }\n  \n  private async processResults(data: AsyncIterator<OhlcvDto>): Promise<void> {\n    // Process in batches\n    const batchSize = this.options.batchSize || 1000;\n    let batch: OhlcvDto[] = [];\n    \n    for await (const bar of data) {\n      batch.push(bar);\n      \n      if (batch.length >= batchSize) {\n        await this.repository.appendBatch(batch);\n        batch = [];\n      }\n    }\n    \n    // Store any remaining items\n    if (batch.length > 0) {\n      await this.repository.appendBatch(batch);\n    }\n    \n    // Store transform coefficients\n    for (const transform of this.transforms) {\n      const coefficients = transform.getCoefficients();\n      if (coefficients) {\n        // Store coefficients in repository\n      }\n    }\n  }\n}\n```",
        "testStrategy": "1. Unit tests for each bar generator\n2. Test with various threshold values\n3. Verify bar properties are correctly calculated\n4. Test server mode with simulated real-time data\n5. Verify gap detection and backfill mechanism\n6. Test graceful shutdown and restart\n7. Integration tests with full pipeline in server mode",
        "priority": "low",
        "dependencies": [
          1,
          4,
          5,
          6
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-04T20:49:04.828Z",
      "updated": "2025-07-04T20:49:04.828Z",
      "description": "Tasks for master context"
    }
  }
}